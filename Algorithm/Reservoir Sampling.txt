http://en.wikipedia.org/wiki/Reservoir_sampling

Reservoir sampling
From Wikipedia, the free encyclopedia

[hide]This article has multiple issues. Please help improve it or discuss these issues on the talk page.
This article may be confusing or unclear to readers. (December 2009)
This article needs attention from an expert in computing. (February 2010)
Reservoir sampling is a family of randomized algorithms for randomly choosing a sample of k items from a list S containing n items, where n is either a very large or unknown number. Typically n is large enough that the list doesn't fit into main memory. The most common example was labelled Algorithm R by Jeffrey Vitter in his paper on the subject.[1]

This simple O(n) algorithm as described in the Dictionary of Algorithms and Data Structures[2] consists of the following steps (assuming that the arrays are one-based, and that the number of items to select, k, is smaller than the size of the source array, S):

array R[k];    // result
integer i, j;

// fill the reservoir array
for each i in 1 to k do
    R[i] := S[i]
done;

// replace elements with gradually decreasing probability
for each i in k+1 to length(S) do
    j := random(1, i);   // important: inclusive range
    if j <= k then
        R[j] := S[i]
    fi
done
The algorithm creates a "reservoir" array of size k and populates it with the first k items of S. It then iterates through the remaining elements of S until S is exhausted. At the ith element of S, the algorithm generates a random number j between 1 and i. If j is less than k, the jth element of the reservoir array is replaced with the ith element of S. In effect, for all i, the ith element of S is chosen to be included in the reservoir with probability k/i. Similarly, at each iteration the jth element of the reservoir array is chosen to be replaced with probability 1/k * k/i, which simplifies to 1/i. It can be shown that when the algorithm has finished executing, each item in S has equal probability (i.e. k/length(S)) of being chosen for the reservoir.

Contents  [hide] 
1 Relation to Fisher-Yates shuffle
2 Example implementation
3 Statistical properties
4 Limitations
5 See also
6 References
Relation to Fisher-Yates shuffle[edit]
Suppose one wanted to draw k random cards from a deck of playing cards (i.e., n=52). A natural approach would be to shuffle the deck and then take the top k cards. In the general case, the shuffle also needs to work even if the number of cards in the deck is not known in advance, a condition which is satisfied by the inside-out version of the Fisher-Yates shuffle:

To initialize an array a of n elements to a randomly shuffled copy of S, both 0-based:
   a[0] ← S[0]
   for i from 1 to n - 1 do
       r ← random (0 .. i)
       a[i] ← a[r]
       a[r] ← S[i]

Note that although the rest of the cards are shuffled, only the top k are important in the present context. Therefore, the array a need only track the cards in the top k positions while performing the shuffle, reducing the amount of memory needed. Truncating a to length k, the algorithm is modified accordingly:

To initialize an array a to k random elements of S (which is of length n), both 0-based:
   a[0] ← S[0]
   for i from 1 to k - 1 do
       r ← random (0 .. i)
       a[i] ← a[r]
       a[r] ← S[i]

   for i from k to n - 1 do
       r ← random (0 .. i)

       if (r < k) then a[r] ← S[i]
Since the order of the first k cards is immaterial, the first loop can be removed and a can be initialized to be the first k items of S. This yields Algorithm R.

Example implementation[edit]
The following is a simple implementation of the algorithm in Python that samples the set of English Wikipedia page titles:

import random
SAMPLE_COUNT = 10
 
# Force the value of the seed so the results are repeatable
random.seed(12345)
 
sample_titles = []
for index, line in enumerate(open("enwiki-20091103-all-titles-in-ns0")):
        # Generate the reservoir
        if index < SAMPLE_COUNT:
                sample_titles.append(line)
        else:                  
                # Randomly replace elements in the reservoir
                # with a decreasing probability.             
                # Choose an integer between 0 and index (inclusive)               
                r = random.randint(0, index)               
                if r < SAMPLE_COUNT:                       
                        sample_titles[r] = line
print sample_titles
Statistical properties[edit]
Probabilities of selection of the reservoir methods are discussed in Chao (1982)[3] and Tille (2006).[4] While the first-order selection probabilities are equal to k/n (or, in case of Chao's procedure, to an arbitrary set of unequal probabilities), the second order selection probabilities depend on the order in which the records are sorted in the original reservoir. The problem is overcome by the cube sampling method of Deville and Tille (2004).[5]

Limitations[edit]
Reservoir sampling makes the assumption that the desired sample fits into main memory, often implying that k is a constant independent of n. In application where we would like to select a large subset of the input list (say a third, i.e. k=n/3), other methods need to be adopted. Distributed implementations for this problem have been proposed.[6]

See also[edit]
Moving average
Fisher-Yates shuffle
References[edit]
Jump up ^ Random Sampling with a Reservoir
Jump up ^ Dictionary of Algorithms and Data Structures
Jump up ^ Chao, M.T. (1982) A general purpose unequal probability sampling plan. Biometrika, 69 (3): 653-656.
Jump up ^ Tille, Y. (2006). Sampling Algorithms. Springer
Jump up ^ Deville, J.-C., and Y. Tille (2004). Efficient balanced sampling: The cube method. Biometrika 91 (4): 893-912.
Jump up ^ Reservoir Sampling in MapReduce